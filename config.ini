[config]
# cookie 如果为不需要cookie的任务则可不填
Cookie: _lxsdk_cuid=1771fca7715c8-0b76a36e0e15af-4c3f207e-1fa400-1771fca7715c8; _lxsdk=1771fca7715c8-0b76a36e0e15af-4c3f207e-1fa400-1771fca7715c8; Hm_lvt_602b80cf8079ae6591966cc70a3940e7=1614309743,1614317633,1614924618,1615880814; _hc.v=38af1c67-4a50-3220-06f6-bf9f16e71c41.1611146098; s_ViewType=10; ua=Anthony_2255; ctu=45dc2c9dbeb503a51745ea28aa40fe6f6ec4ce4bca48aa2424fe6332cfd8b8d1; Hm_lvt_4c4fc10949f0d691f3a2cc4ca5065397=1611653073; aburl=1; Hm_lvt_dbeeb675516927da776beeb1d9802bd4=1611728167; cy=19; fspop=test; _lxsdk_s=1783a007d9d-326-632-cdc%7C%7C34; Hm_lpvt_602b80cf8079ae6591966cc70a3940e7=1615880835; lgtoken=0fa9f9b53-ec3d-4be3-bcc7-6afc999724f4; thirdtoken=5ac9eff4-d97d-4604-b11a-fb2bcde0c155; dplet=2777078583d896040d6434385dce9cd4; dper=fc918684d6a5423228124f4d66b0fb417d64840d8819f34e7c48475d9149f994bb4b1b206ac6bdc2d65501ab9a1ffc2fea0a5ed5074ea0915f91298561e691a1e0b48a86d1c5e2ed376b182cd7e6ddc33c6d9f2ec7fb5b7881f602fbc80164d4; ll=7fd06e815b796be3df069dec7836c3df; ctu=4525a0f2c414ada41ff73a83012b0cec7d0d31b9504d22fb86e7f7ecc36ccdbd222ecf472b807f448f618195bfe59746
# 默认user-agent,如果为None则为随机（仅可在不需要cookie的任务中使用,登录状态不建议随机user-agent）
user-agent = Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:84.0) Gecko/20100101 Firefox/84.0
# 保存方式  暂时支持csv和mongodb
save_mode = mongo
# mongodb 链接 （mongodb://servername:port，如果本地默认端口（27017）可不填）
mongo_path = mongodb://server2.sniper97.cn:27777
# 累计请求多少次休息多少秒，从小到大排列。例：1,2;5,10 代表每请求1次休息2秒，每5次休息10秒。
requests_times = 1,2;3,5;10,50
[detail]
# 搜索关键字
keyword = 火锅
# 位置代号，如上海为1  北京为2 广州为4，暂时不支持地名自动转换id
location_id = 19
# 频道号
channel_id = 0
# 搜索页链接，用于非'http://www.dianping.com/search/keyword/(location_id)/(channel_id)_(key_word)/p(page_nub)的情况
# 如果不填，则默认填充上述url，填充后上述参数默认无效
# 注，填充的时候需要填充到p，例如：http://www.dianping.com/dalian/ch10/g110p2 填充http://www.dianping.com/dalian/ch10/g110p
search_url = http://www.dianping.com/dalian/ch10/g110p
# 需要详情页,需要为1，不需要为0
need_detail = 1
# 需要评论,需要为1，不需要为0。（由于大众点评反爬机制较为严格，需要执行严格的休息时间防ban，此条置为1会严重拖慢爬取速度）
need_comment = 0
# 是否只需要搜索页的首条内容
need_first = False
# 需要搜索的页数
need_pages = 10
[save]
# 保存评论的页数
review_pages = 1